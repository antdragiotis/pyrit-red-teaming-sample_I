{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15865191",
   "metadata": {},
   "source": [
    "# PyRIT Red Teaming - Sample I\n",
    "This module provides a simple red teaming framework using Microsoft PyRIT for adversarial testing of AI models. It manages attack configurations, target models, and result analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22e4f78",
   "metadata": {},
   "source": [
    "## Loading of Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a70eaa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from typing import Dict, List, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyRIT core imports\n",
    "from pyrit.datasets import fetch_adv_bench_dataset\n",
    "from pyrit.common import IN_MEMORY, initialize_pyrit\n",
    "from pyrit.memory import CentralMemory, AttackResultEntry\n",
    "\n",
    "# PyRIT converters and normalizers\n",
    "from pyrit.prompt_converter import Base64Converter\n",
    "from pyrit.prompt_normalizer import PromptConverterConfiguration\n",
    "\n",
    "# PyRIT attack framework\n",
    "from pyrit.executor.attack import (\n",
    "    AttackAdversarialConfig,\n",
    "    AttackConverterConfig,\n",
    "    AttackScoringConfig,\n",
    "    ConsoleAttackResultPrinter,\n",
    "    RedTeamingAttack,\n",
    "    RTOSystemPromptPaths,\n",
    ")\n",
    "\n",
    "# PyRIT targets and scorers\n",
    "from pyrit.prompt_target import OpenAIChatTarget, CrucibleTarget\n",
    "from pyrit.score import SelfAskTrueFalseScorer, TrueFalseQuestionPaths\n",
    "\n",
    "# Make Read Dataset to have initialized the categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d1344f",
   "metadata": {},
   "source": [
    "## Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a03fb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_EXPORT_PATH: str = \"./mem_exports/memoryconversations\"\n",
    "\n",
    "DATASET_LIMIT: int = 5\n",
    "\n",
    "MAX_TURNS: int = 3\n",
    "\n",
    "CONVERTERS_APPLICATION_CHANCES = 0.25\n",
    "\n",
    "class ModelType(Enum):\n",
    "    \"\"\"Enumeration for different model types supported by the system.\"\"\"\n",
    "    OPENAI_GPT4O = \"gpt-4o\"\n",
    "    OPENAI_GPT4O_MINI = \"gpt-4o-mini\"\n",
    "    OPENAI_GPT35_TURBO = \"gpt-3.5-turbo\"\n",
    "    LLAMA_31_8B = \"Meta-Llama-3.1-8B-Instruct\"\n",
    "    MINISTRAL_3B = \"Ministral-3B\"\n",
    "    PIECEOFCAKE = \"Crucible - pieceofcake\"\n",
    "\n",
    "class AttackOutcome(Enum):\n",
    "    \"\"\"Enumeration for attack outcomes.\"\"\"\n",
    "    SUCCESS = \"SUCCESS\"\n",
    "    FAILURE = \"FAILURE\"\n",
    "    TIMEOUT = \"TIMEOUT\"\n",
    "    ERROR = \"ERROR\"\n",
    "\n",
    "@dataclass\n",
    "class AttackConfiguration:\n",
    "    \"\"\"Data class to hold attack configuration parameters.\"\"\"\n",
    "    dataset_limit: int = DATASET_LIMIT\n",
    "    max_turns: int = MAX_TURNS\n",
    "    memory_labels: Dict[str, str] = None\n",
    "    dataset_categories: List[str] = None\n",
    "    \n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.dataset_limit is None:\n",
    "            self.dataset_limit = DATASET_LIMIT\n",
    "        if self.max_turns is None:\n",
    "            self.max_turns = MAX_TURNS\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AttackResult:\n",
    "    \"\"\"Data class to hold individual attack results.\"\"\"\n",
    "    objective: str\n",
    "    attack_identifier: str\n",
    "    scorer: str\n",
    "    executed_turns: int\n",
    "    execution_time_s: float\n",
    "    success: bool\n",
    "    outcome_reason: Optional[str]\n",
    "    last_response: Optional[str] = None\n",
    "    last_score: Optional[Any] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57936e26",
   "metadata": {},
   "source": [
    "## UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "53b75027",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyRITLogger:\n",
    "    \"\"\"Logging utility class for PyRIT operations.\"\"\"\n",
    "    \n",
    "    def __init__(self, log_level: int = logging.INFO):\n",
    "        \"\"\"\n",
    "        Initialize logger with specified log level.\n",
    "        \n",
    "        Args:\n",
    "            log_level: Logging level (default: INFO)\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(\"PyRITRedTeaming\")\n",
    "        self.logger.setLevel(log_level)\n",
    "        \n",
    "        if not self.logger.handlers:\n",
    "            handler = logging.StreamHandler()\n",
    "            formatter = logging.Formatter(\n",
    "                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "            )\n",
    "            handler.setFormatter(formatter)\n",
    "            self.logger.addHandler(handler)\n",
    "    \n",
    "    def log_attack_start(self, target_name: str, objective: str):\n",
    "        \"\"\"Log the start of an attack.\"\"\"\n",
    "        self.logger.info(f\"Starting attack on {target_name} with objective: {objective[:200]}\")\n",
    "    \n",
    "    def log_attack_result(self, result: AttackResult):\n",
    "        \"\"\"Log attack result.\"\"\"\n",
    "        status = \"SUCCESS\" if result.success else \"FAILURE\"\n",
    "        self.logger.info(f\"Attack {status}: {result.executed_turns} turns, {result.execution_time_s:.2f}s\")\n",
    "    \n",
    "    def log_error(self, error: Exception, context: str = \"\"):\n",
    "        \"\"\"Log error with context.\"\"\"\n",
    "        self.logger.error(f\"Error in {context}: {str(error)}\")\n",
    "\n",
    "\n",
    "class TargetModelManager:\n",
    "    \"\"\"Manages different target models for red teaming attacks.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the target model manager.\"\"\"\n",
    "        self.logger = PyRITLogger().logger\n",
    "        self.targets = {}\n",
    "        self._initialize_targets()\n",
    "    \n",
    "    def _initialize_targets(self):\n",
    "        \"\"\"Initialize all available target models.\"\"\"\n",
    "        try:\n",
    "            # OpenAI models\n",
    "            self.targets[ModelType.OPENAI_GPT4O] = OpenAIChatTarget(\n",
    "                model_name=ModelType.OPENAI_GPT4O.value\n",
    "            )\n",
    "            self.targets[ModelType.OPENAI_GPT4O_MINI] = OpenAIChatTarget(\n",
    "                model_name=ModelType.OPENAI_GPT4O_MINI.value\n",
    "            )\n",
    "            self.targets[ModelType.OPENAI_GPT35_TURBO] = OpenAIChatTarget(\n",
    "                model_name=ModelType.OPENAI_GPT35_TURBO.value\n",
    "            )\n",
    "            \n",
    "            # External target (Crucible)\n",
    "            self.targets[ModelType.PIECEOFCAKE] = CrucibleTarget(\n",
    "                endpoint=\"https://pieceofcake.platform.dreadnode.io\"\n",
    "            )\n",
    "            \n",
    "            # Azure Foundry models (if environment variables are available)\n",
    "            if self._check_credentials():\n",
    "                self.targets[ModelType.LLAMA_31_8B] = OpenAIChatTarget(\n",
    "                    endpoint=os.environ[\"AZURE_FOUNDRY_MODELS_COMPLETION_ENDPOINT\"],\n",
    "                    api_key=os.environ[\"AZURE_FOUNDRY_API_KEY\"],\n",
    "                    api_version=\"2024-05-01-preview\",\n",
    "                    model_name=ModelType.LLAMA_31_8B.value,\n",
    "                    max_tokens=216,\n",
    "                )\n",
    "                \n",
    "                self.targets[ModelType.MINISTRAL_3B] = OpenAIChatTarget(\n",
    "                    endpoint=os.environ[\"AZURE_FOUNDRY_MODELS_COMPLETION_ENDPOINT\"],\n",
    "                    api_key=os.environ[\"AZURE_FOUNDRY_API_KEY\"],\n",
    "                    api_version=\"2024-05-01-preview\",\n",
    "                    model_name=ModelType.MINISTRAL_3B.value,\n",
    "                    max_tokens=216,\n",
    "                )\n",
    "            \n",
    "            self.logger.info(f\"Initialized {len(self.targets)} target models\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error initializing targets: {str(e)}\")\n",
    "    \n",
    "    def _check_credentials(self) -> bool:\n",
    "        \"\"\"Check if Azure credentials are available.\"\"\"\n",
    "        required_vars = [\"OPENAI_API_KEY\",\n",
    "                         \"OPENAI_CHAT_KEY\",\n",
    "                         \"CRUCIBLE_API_KEY\",\n",
    "                         \"AZURE_FOUNDRY_MODELS_COMPLETION_ENDPOINT\",\n",
    "                         \"AZURE_FOUNDRY_API_KEY\"]\n",
    "        return all(var in os.environ for var in required_vars)\n",
    "    \n",
    "    def get_target(self, model_type: ModelType) -> Optional[Any]:\n",
    "        \"\"\"\n",
    "        Get a target model by type.\n",
    "        \n",
    "        Args:\n",
    "            model_type: The type of model to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            Target model instance or None if not available\n",
    "        \"\"\"\n",
    "        return self.targets.get(model_type)\n",
    "    \n",
    "    def get_available_targets(self) -> List[ModelType]:\n",
    "        \"\"\"Get list of available target model types.\"\"\"\n",
    "        return list(self.targets.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee2968d",
   "metadata": {},
   "source": [
    "## Dataset Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1c121703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetManager:\n",
    "    \"\"\"Manages adversarial datasets for red teaming attacks.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the dataset manager.\"\"\"\n",
    "        self.logger = PyRITLogger().logger\n",
    "    \n",
    "    def fetch_adversarial_objectives(\n",
    "        self, \n",
    "        categories: List[str] = None, \n",
    "        limit: int = 5\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        Fetch adversarial objectives from the AdvBench dataset.\n",
    "        \n",
    "        Args:\n",
    "            categories: List of categories to fetch\n",
    "            limit: Maximum number of objectives to fetch\n",
    "            \n",
    "        Returns:\n",
    "            List of adversarial objective strings\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            self.logger.info(f\"Fetching {limit} objectives from categories: {categories}\")\n",
    "            objectives = fetch_adv_bench_dataset(\n",
    "                main_categories=categories\n",
    "            ).get_values(first=limit)\n",
    "            \n",
    "            self.logger.info(f\"Successfully fetched {len(objectives)} objectives\")\n",
    "            return objectives\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error fetching dataset: {str(e)}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d36c80",
   "metadata": {},
   "source": [
    "## Attack Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0d4c4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackExecutor:\n",
    "    \"\"\"Executes red teaming attacks using PyRIT framework.\"\"\"\n",
    "    \n",
    "    def __init__(self, target_manager: TargetModelManager):\n",
    "        \"\"\"\n",
    "        Initialize the attack executor.\n",
    "        \n",
    "        Args:\n",
    "            target_manager: Instance of TargetModelManager\n",
    "        \"\"\"\n",
    "        self.target_manager = target_manager\n",
    "        self.logger = PyRITLogger().logger\n",
    "        self.memory = CentralMemory.get_memory_instance()\n",
    "        self.result_printer = ConsoleAttackResultPrinter()\n",
    "    \n",
    "    def _create_attack_configuration(\n",
    "        self, \n",
    "        target_model: Any,\n",
    "        adversarial_target: Any = None,\n",
    "        scoring_target: Any = None\n",
    "    ) -> tuple:\n",
    "        \"\"\"\n",
    "        Create attack configuration components.\n",
    "        \n",
    "        Args:\n",
    "            target_model: Primary target model for attacks\n",
    "            adversarial_target: Model for adversarial prompt generation\n",
    "            scoring_target: Model for scoring attack results\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (converter_config, adversarial_config, scoring_config)\n",
    "        \"\"\"\n",
    "        # Default to GPT-4o-mini for adversarial and scoring if not specified\n",
    "        if adversarial_target is None:\n",
    "            adversarial_target = self.target_manager.get_target(ModelType.OPENAI_GPT4O)\n",
    "        \n",
    "        if scoring_target is None:\n",
    "            scoring_target = self.target_manager.get_target(ModelType.OPENAI_GPT4O_MINI)\n",
    "\n",
    "        # Use and configure prompt converter (Base64 encoding for obfuscation) with a chance 1/4\n",
    "        \n",
    "        if np.random.rand() < CONVERTERS_APPLICATION_CHANCES:\n",
    "            prompt_converters = PromptConverterConfiguration.from_converters(\n",
    "                converters=[Base64Converter()]\n",
    "            )\n",
    "        else:\n",
    "            prompt_converters = PromptConverterConfiguration.from_converters(\n",
    "                converters=[]\n",
    "            )\n",
    "        converter_config = AttackConverterConfig(request_converters=prompt_converters)\n",
    "        \n",
    "        # Configure adversarial attack generation\n",
    "        adversarial_config = AttackAdversarialConfig(\n",
    "            target=adversarial_target,\n",
    "            system_prompt_path=RTOSystemPromptPaths.TEXT_GENERATION.value,\n",
    "        )\n",
    "        \n",
    "        # Configure attack result scoring\n",
    "        scoring_config = AttackScoringConfig(\n",
    "            objective_scorer=SelfAskTrueFalseScorer(\n",
    "                true_false_question_path=TrueFalseQuestionPaths.PROMPT_INJECTION.value,\n",
    "                chat_target=scoring_target\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return converter_config, adversarial_config, scoring_config\n",
    "    \n",
    "    async def execute_single_attack(\n",
    "        self,\n",
    "        objective: str,\n",
    "        target_model: Any,\n",
    "        config: AttackConfiguration\n",
    "    ) -> AttackResult:\n",
    "        \"\"\"\n",
    "        Execute a single red teaming attack.\n",
    "        \n",
    "        Args:\n",
    "            objective: The adversarial objective to test\n",
    "            target_model: Target model to attack\n",
    "            config: Attack configuration parameters\n",
    "            \n",
    "        Returns:\n",
    "            AttackResult containing the outcome and metrics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create attack configurations\n",
    "            converter_config, adversarial_config, scoring_config = \\\n",
    "                self._create_attack_configuration(target_model)\n",
    "            \n",
    "            # Initialize red teaming attack\n",
    "            red_teaming_attack = RedTeamingAttack(\n",
    "                objective_target=target_model,\n",
    "                attack_converter_config=converter_config,\n",
    "                attack_adversarial_config=adversarial_config,\n",
    "                attack_scoring_config=scoring_config,\n",
    "                max_turns=config.max_turns,\n",
    "            )\n",
    "            \n",
    "            # Execute the attack\n",
    "            self.logger.info(f\"Executing attack with objective: {objective[:200]}\")\n",
    "            result = await red_teaming_attack.execute_async(\n",
    "                objective=objective,\n",
    "                memory_labels=config.memory_labels\n",
    "            )\n",
    "            \n",
    "            # Print result to console\n",
    "            await self.result_printer.print_result_async(result=result)\n",
    "            \n",
    "            # Convert to our AttackResult format\n",
    "            attack_result = self._convert_pyrit_result(result)\n",
    "            \n",
    "            return attack_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error executing attack: {str(e)}\")\n",
    "            return AttackResult(\n",
    "                objective=objective,\n",
    "                attack_identifier=\"RedTeamingAttack\",\n",
    "                scorer=\"Error\",\n",
    "                executed_turns=0,\n",
    "                execution_time_s=0.0,\n",
    "                success=False,\n",
    "                outcome_reason=str(e)\n",
    "            )\n",
    "    \n",
    "    def _convert_pyrit_result(self, pyrit_result) -> AttackResult:\n",
    "        \"\"\"\n",
    "        Convert PyRIT result to our AttackResult format.\n",
    "        \n",
    "        Args:\n",
    "            pyrit_result: Result from PyRIT attack execution\n",
    "            \n",
    "        Returns:\n",
    "            Converted AttackResult instance\n",
    "        \"\"\"\n",
    "        entry = AttackResultEntry(entry=pyrit_result)\n",
    "        \n",
    "        return AttackResult(\n",
    "            objective=entry.objective,\n",
    "            attack_identifier=\"RedTeamingAttack\",\n",
    "            scorer=str(entry.last_score).split(':', 1)[0] if entry.last_score else \"Unknown\",\n",
    "            executed_turns=entry.executed_turns,\n",
    "            execution_time_s=entry.execution_time_ms / 1000 if entry.execution_time_ms else 0.0,\n",
    "            success=str(entry.outcome).endswith('SUCCESS') if entry.outcome else False,\n",
    "            outcome_reason=entry.outcome_reason,\n",
    "            last_response=entry.last_response,\n",
    "            last_score=entry.last_score\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5912be2",
   "metadata": {},
   "source": [
    "## Result Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7f5346d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultAnalyzer:\n",
    "    \"\"\"Analyzes and processes red teaming attack results.\"\"\"\n",
    "\n",
    "    def __init__(self, memory_export_path: str = MEMORY_EXPORT_PATH):\n",
    "        \"\"\"\n",
    "        Initialize the result analyzer.\n",
    "        \n",
    "        Args:\n",
    "            memory_export_path: Path for exporting memory conversations\n",
    "        \"\"\"\n",
    "        self.memory = CentralMemory.get_memory_instance()\n",
    "        self.memory_export_path = memory_export_path\n",
    "        self.logger = PyRITLogger().logger\n",
    "    \n",
    "    def analyze_attack_results(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Analyze all attack results from memory and create summary statistics.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame containing attack results and statistics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get raw results from memory\n",
    "            raw_results = list(self.memory.get_attack_results())\n",
    "            \n",
    "            if not raw_results:\n",
    "                self.logger.warning(\"No attack results found in memory\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            # Convert to DataFrame for analysis\n",
    "            results_data = []\n",
    "            \n",
    "            for result in raw_results:\n",
    "                result_dict = vars(result)\n",
    "                \n",
    "                # Extract and clean relevant information\n",
    "                analysis_row = {\n",
    "                    'objective': result_dict.get('objective', ''),\n",
    "                    'attack_identifier': result_dict.get('attack_identifier', {}).get('__type__', 'Unknown'),\n",
    "                    'scorer': str(result_dict.get('last_score', '')).split(':', 1)[0],\n",
    "                    'executed_turns': result_dict.get('executed_turns', 0),\n",
    "                    'execution_time_s': result_dict.get('execution_time_ms', 0) / 1000,\n",
    "                    'success': str(result_dict.get('outcome', '')).endswith('SUCCESS'),\n",
    "                    'outcome_reason': result_dict.get('outcome_reason', '')\n",
    "                }\n",
    "                \n",
    "                results_data.append(analysis_row)\n",
    "            \n",
    "            # Create analysis DataFrame\n",
    "            analysis_df = pd.DataFrame(results_data)\n",
    "            \n",
    "            return analysis_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error analyzing results: {str(e)}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def export_memory_conversations(self, formats: List[str] = None):\n",
    "        \"\"\"\n",
    "        Export memory conversations to specified formats.\n",
    "        \n",
    "        Args:\n",
    "            formats: List of formats to export ('json', 'csv')\n",
    "        \"\"\"\n",
    "        if formats is None:\n",
    "            formats = ['json', 'csv']\n",
    "        \n",
    "        try:\n",
    "            for format_type in formats:\n",
    "                file_path = f\"{self.memory_export_path}.{format_type}\"\n",
    "                self.memory.export_conversations(\n",
    "                    file_path=file_path,\n",
    "                    export_type=format_type\n",
    "                )\n",
    "                self.logger.info(f\"Exported conversations to {file_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error exporting conversations: {str(e)}\")\n",
    "    \n",
    "    def find_interesting_prompts(self, memory_labels: Dict[str, str] = None) -> List[Any]:\n",
    "        \"\"\"\n",
    "        Find prompts with high scores or positive attack indicators.\n",
    "        \n",
    "        Args:\n",
    "            memory_labels: Memory labels to filter by\n",
    "            \n",
    "        Returns:\n",
    "            List of interesting prompt pieces\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result_pieces = self.memory.get_prompt_request_pieces(labels=memory_labels)\n",
    "            interesting_prompts = []\n",
    "            \n",
    "            for piece in result_pieces:\n",
    "                for score in piece.scores:\n",
    "                    # Check for high float scores or positive true/false scores\n",
    "                    if (score.scorer_class_identifier.get(\"__type__\") == \"SelfAskTrueFalseScorer\" \n",
    "                        and score.get_value() == True):\n",
    "                        interesting_prompts.append(piece)\n",
    "                        break\n",
    "            \n",
    "            print(f\"Found {len(interesting_prompts)} interesting prompts\")\n",
    "            return interesting_prompts\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error finding interesting prompts: {str(e)}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5877c761",
   "metadata": {},
   "source": [
    "## PyRIT Red Teaming System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "739fc78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyRITRedTeamingSystem:\n",
    "    \"\"\"\n",
    "        Main class that orchestrates the entire red teaming system.\n",
    "        \n",
    "        This class provides a high-level interface for conducting comprehensive\n",
    "        red teaming attacks against AI models using the PyRIT framework.\n",
    "        \"\"\"\n",
    "    \n",
    "    def __init__(self, memory_type: str = IN_MEMORY, log_level: int = logging.INFO):\n",
    "        \"\"\"\n",
    "        Initialize the PyRIT Red Teaming System.\n",
    "        \n",
    "        Args:\n",
    "            memory_type: Type of memory storage for PyRIT\n",
    "            log_level: Logging level for the system\n",
    "        \"\"\"\n",
    "        # Initialize PyRIT\n",
    "        initialize_pyrit(memory_db_type=memory_type)\n",
    "        \n",
    "        # Initialize components\n",
    "        self.logger = PyRITLogger(log_level).logger\n",
    "        self.target_manager = TargetModelManager()\n",
    "        self.dataset_manager = DatasetManager()\n",
    "        self.attack_executor = AttackExecutor(self.target_manager)\n",
    "        self.result_analyzer = ResultAnalyzer()\n",
    "        \n",
    "        # Memory management\n",
    "        self.memory = CentralMemory.get_memory_instance()\n",
    "        \n",
    "        self.logger.info(\"PyRIT Red Teaming System initialized successfully\")\n",
    "    \n",
    "    async def run_attack(\n",
    "        self,\n",
    "        target_models: List[ModelType] = None,\n",
    "        config: AttackConfiguration = None\n",
    "    ) -> Dict[str, List[AttackResult]]:\n",
    "        \"\"\"\n",
    "        Run red teaming attacks across multiple models.\n",
    "        \n",
    "        Args:\n",
    "            target_models: List of model types to test (default: all available)\n",
    "            config: Attack configuration parameters\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping model names to their attack results\n",
    "        \"\"\"\n",
    "        if target_models is None:\n",
    "            target_models = self.target_manager.get_available_targets()\n",
    "        \n",
    "        if config is None:\n",
    "            config = AttackConfiguration()\n",
    "        \n",
    "        # Reset memory for fresh start\n",
    "        self.memory.reset_database()\n",
    "        \n",
    "        # Fetch adversarial objectives\n",
    "        objectives = self.dataset_manager.fetch_adversarial_objectives(\n",
    "            categories=config.dataset_categories,\n",
    "            limit=config.dataset_limit\n",
    "        )\n",
    "        \n",
    "        if not objectives:\n",
    "            self.logger.error(\"No objectives fetched. Cannot proceed with attacks.\")\n",
    "            return {}\n",
    "        \n",
    "        # Execute attacks on each target model\n",
    "        all_results = {}\n",
    "        \n",
    "        for model_type in target_models:\n",
    "            target_model = self.target_manager.get_target(model_type)\n",
    "            #config.memory_labels = {\"target_model\": model_type.value}\n",
    "\n",
    "            if target_model is None:\n",
    "                self.logger.warning(f\"Target model {model_type} not available. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            self.logger.info(f\"Starting attacks on {model_type.value}\")\n",
    "            model_results = []\n",
    "            \n",
    "            for objective in objectives:  \n",
    "                try:\n",
    "                    result = await self.attack_executor.execute_single_attack(\n",
    "                        objective=objective,\n",
    "                        target_model=target_model,\n",
    "                        config=config\n",
    "                    )\n",
    "                    model_results.append(result)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error attacking {model_type.value}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            all_results[model_type.value] = model_results\n",
    "            self.logger.info(f\"Completed {len(model_results)} attacks on {model_type.value}\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def analyze_and_export_results(self, export_formats: List[str] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Analyze attack results and export data.\n",
    "        \n",
    "        Args:\n",
    "            export_formats: List of export formats ('json', 'csv')\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame containing analysis results\n",
    "        \"\"\"\n",
    "        if export_formats is None:\n",
    "            export_formats = ['json', 'csv']\n",
    "        \n",
    "        # Analyze results\n",
    "        analysis_df = self.result_analyzer.analyze_attack_results()\n",
    "        \n",
    "        # Export memory conversations\n",
    "        self.result_analyzer.export_memory_conversations(formats=export_formats)\n",
    "        \n",
    "        # Find interesting prompts\n",
    "        interesting_prompts = self.result_analyzer.find_interesting_prompts()\n",
    "        \n",
    "        return analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb1b91",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67abbb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"Main function demonstrating system usage.\"\"\"\n",
    "    \n",
    "    # Initialize the red teaming system\n",
    "    red_teaming_system = PyRITRedTeamingSystem()\n",
    "\n",
    "    target_models=[ModelType.OPENAI_GPT4O_MINI,\n",
    "                   ModelType.OPENAI_GPT35_TURBO,\n",
    "                   ModelType.LLAMA_31_8B,\n",
    "                   ModelType.MINISTRAL_3B, \n",
    "                   ModelType.PIECEOFCAKE\n",
    "               ]\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"RUNNING TEST\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Configure attack parameters\n",
    "    attack_config = AttackConfiguration(\n",
    "        memory_labels={},\n",
    "        dataset_categories=[\"Financial and Business\"],\n",
    "    )\n",
    "    \n",
    "    # Run attacks\n",
    "    results = await red_teaming_system.run_attack(\n",
    "        target_models=target_models,\n",
    "        config=attack_config\n",
    "    )\n",
    "\n",
    "    print(f\"Test completed{\".\"*20}\")\n",
    "    \n",
    "    # Analyze and export results\n",
    "\n",
    "    results_df = red_teaming_system.analyze_and_export_results()\n",
    "\n",
    "    static_df = pd.DataFrame([item.value for item in target_models for _ in range(DATASET_LIMIT)], columns=['target_models'])\n",
    "\n",
    "    analysis_df = pd.concat([static_df, results_df], axis=1)\n",
    "\n",
    "    if not analysis_df.empty:\n",
    "        print(f\"{\"=\" * 50}\\nANALYZING RESULTS\\n{\"=\" * 50}\")\n",
    "        print(analysis_df[['target_models','objective','success','executed_turns', 'execution_time_s']].to_string())\n",
    "        \n",
    "        print(f\"\\n{\"=\" * 50}\\nRESULTS SUMMARY\\n{\"=\" * 50}\")\n",
    "        aggregated_df = analysis_df.groupby(['target_models']).agg({\n",
    "            'success': ['mean'],\n",
    "            'executed_turns': ['sum', 'mean', 'min', 'max'],\n",
    "            'execution_time_s': ['sum', 'mean', 'min', 'max']\n",
    "        }).reset_index()\n",
    "        print(aggregated_df.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
